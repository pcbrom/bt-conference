{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import multiprocessing\n",
    "import jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              abstract  Repetition  \\\n",
      "0    文章首先阐述了工程教育专业认证与应用化学专业生产实习课程的关联，然后论述了工程教育专业认证背...           1   \n",
      "1    文章首先阐述了工程教育专业认证与应用化学专业生产实习课程的关联，然后论述了工程教育专业认证背...           2   \n",
      "2    文章首先阐述了工程教育专业认证与应用化学专业生产实习课程的关联，然后论述了工程教育专业认证背...           3   \n",
      "3    “天然药物化学”是高等学校药学及相关专业的必修课程。课程章节内容多、理论性强,学生学习面临较...           1   \n",
      "4    “天然药物化学”是高等学校药学及相关专业的必修课程。课程章节内容多、理论性强,学生学习面临较...           2   \n",
      "..                                                 ...         ...   \n",
      "529  <正>化学作为一门自然科学，是人们认识世界和改造世界的重要途径。在历史长河中，化学是经由无数...           2   \n",
      "530  <正>化学作为一门自然科学，是人们认识世界和改造世界的重要途径。在历史长河中，化学是经由无数...           3   \n",
      "531  绿色化学分析技术，即最大限度地减少或者避免有害化学品被应用于分析过程当中，从而实现环境保护与...           1   \n",
      "532  绿色化学分析技术，即最大限度地减少或者避免有害化学品被应用于分析过程当中，从而实现环境保护与...           2   \n",
      "533  绿色化学分析技术，即最大限度地减少或者避免有害化学品被应用于分析过程当中，从而实现环境保护与...           3   \n",
      "\n",
      "                                                 ZH_EN  \\\n",
      "0    The article first elaborates on the connection...   \n",
      "1    The article first elaborates on the relationsh...   \n",
      "2    The article first elucidates the relationship ...   \n",
      "3    Natural Product Chemistry is a required course...   \n",
      "4    \"Natural Products Chemistry\" is a required cou...   \n",
      "..                                                 ...   \n",
      "529  Chemistry, as a natural science, is an importa...   \n",
      "530  Chemistry, as a natural science, is an importa...   \n",
      "531  Green chemical analysis technology aims to min...   \n",
      "532  Green chemical analysis technology aims to min...   \n",
      "533  Green chemical analysis technology aims to min...   \n",
      "\n",
      "                                                 EN_ZH  model  \n",
      "0    文章首先阐述了工程教育专业认证与应用化学专业生产实习课程之间的联系。接着，探讨了在工程教育专...  G2FTE  \n",
      "1    文章首先阐述了工程教育专业认证与应用化学专业生产实习课程之间的关系。其次，探讨了在工程教育专...  G2FTE  \n",
      "2    文章首先阐述工程教育专业认证与应用化学生产实习课程的关系。然后探讨工程教育专业认证背景下应用...  G2FTE  \n",
      "3    天然产物化学是高等院校药学及相关专业的必修课。课程内容章节丰富且理论性强，学生在学习中面临诸...  G2FTE  \n",
      "4    天然药物化学是高校药学及相关专业的必修课。该课程内容广泛且理论性强，对学生的学习造成挑战。因...  G2FTE  \n",
      "..                                                 ...    ...  \n",
      "529  化学作为一门自然科学，是认识和改造世界的重要途径。纵观历史，化学在无数次的实验探索中逐步发展...   DSV3  \n",
      "530  化学作为一门自然科学，是人类认识和改造世界的重要途径。纵观历史，化学在无数次的实验探索中逐步...   DSV3  \n",
      "531  绿色化学分析技术旨在最小化或避免在分析过程中使用有害化学品，从而实现环境保护和可持续发展。文...   DSV3  \n",
      "532  绿色化学分析技术旨在分析过程中尽量减少或避免使用有害化学品，从而实现环境保护和可持续发展。文...   DSV3  \n",
      "533  绿色化学分析技术旨在分析过程中尽量减少或避免使用有害化学品，从而实现环境保护和可持续发展。文...   DSV3  \n",
      "\n",
      "[534 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "\n",
    "df_gemini = pd.read_csv(\"results_data/experimental_design_results_gemini-2.0-flash-thinking-exp_reprocessed.csv\")\n",
    "df_gemini['model'] = 'G2FTE' # gemini-2.0-flash-thinking-exp\n",
    "\n",
    "df_deepseek = pd.read_csv(\"results_data/experimental_design_results_deepseek-chat.csv\")\n",
    "df_deepseek['model'] = 'DSV3' # deepseek-chat v3\n",
    "\n",
    "# Stack data frames\n",
    "df = pd.concat([df_gemini, df_deepseek], ignore_index=True)\n",
    "\n",
    "# Print\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/bt-conference/.venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.883 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.898 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.904 seconds.\n",
      "Loading model cost 0.913 seconds.\n",
      "Loading model cost 0.909 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Prefix dict has been built successfully.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.921 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.925 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.928 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.939 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.971 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.977 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.981 seconds.\n",
      "Loading model cost 0.977 seconds.\n",
      "Loading model cost 0.986 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.986 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.983 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.000 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/bt-conference/.venv/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Loading model cost 1.045 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/bt-conference/.venv/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Loading model cost 1.097 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 1.113 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization function for Chinese texts using Jieba\n",
    "def tokenize_chinese_jieba(text):\n",
    "    # Use Jieba to cut the Chinese text into words\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# Function to calculate BLEU (using unigram and bigram)\n",
    "def calculate_bleu(candidate_tokens, reference_tokens):\n",
    "    # We use weights (0.5, 0.5) for unigrams and bigrams\n",
    "    try:\n",
    "        return sentence_bleu([reference_tokens], candidate_tokens, weights=(0.5, 0.5, 0, 0))\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "# Function to calculate CHRF (character n-gram F-score)\n",
    "def calculate_chrf(candidate_tokens, reference_tokens):\n",
    "    candidate_str = \"\".join(candidate_tokens)\n",
    "    reference_str = \"\".join(reference_tokens)\n",
    "    # Calculates the ratio between the intersection and the union of the characters of the reference\n",
    "    return len(set(candidate_str) & set(reference_str)) / len(set(reference_str)) if len(set(reference_str)) > 0 else 0\n",
    "\n",
    "# Function to calculate TER using TF-IDF vectorization and mean squared error\n",
    "def calculate_ter(candidate_text, reference_text):\n",
    "    vectorizer = TfidfVectorizer() #token_pattern=r\"(?u)\\b\\w+\\b\" - Removed token pattern because it is not needed for chinese\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([candidate_text, reference_text])\n",
    "        return mean_squared_error(tfidf_matrix[0].toarray(), tfidf_matrix[1].toarray())\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "# Function to calculate Semantic Similarity (TF-IDF + cosine)\n",
    "def calculate_semantic_similarity(original, translated):\n",
    "    vectorizer = TfidfVectorizer() #token_pattern=r\"(?u)\\b\\w+\\b\" - Removed token pattern because it is not needed for chinese\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([original, translated])\n",
    "        return cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "# Apply metrics to each row of the DataFrame\n",
    "def calculate_metrics_for_row(row):\n",
    "    original_text = row['abstract']\n",
    "    back_translation = row['EN_ZH']\n",
    "\n",
    "    # Tokenize the texts using Jieba\n",
    "    original_tokens = tokenize_chinese_jieba(original_text)\n",
    "    translated_tokens = tokenize_chinese_jieba(back_translation)\n",
    "\n",
    "    # Calculate the metrics:\n",
    "    bleu_value = calculate_bleu(translated_tokens, original_tokens)\n",
    "    chrf_value = calculate_chrf(translated_tokens, original_tokens)\n",
    "    ter_value = calculate_ter(\"\".join(translated_tokens), \"\".join(original_tokens))\n",
    "    semantic_similarity = calculate_semantic_similarity(original_text, back_translation)\n",
    "\n",
    "    return pd.Series([bleu_value, chrf_value, ter_value, semantic_similarity])\n",
    "\n",
    "def calculate_metrics_for_df(df):\n",
    "    # tqdm.pandas(desc=\"Calculating metrics\") # Removed progress bar\n",
    "    return df.apply(calculate_metrics_for_row, axis=1)\n",
    "\n",
    "def apply_parallel(df, func, n_cores=multiprocessing.cpu_count()):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = multiprocessing.Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "df[['BLEU', 'CHRF', 'TER', 'Semantic Similarity']] = apply_parallel(df, calculate_metrics_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model                                              EN_ZH      BLEU  \\\n",
      "0    G2FTE  文章首先阐述了工程教育专业认证与应用化学专业生产实习课程之间的联系。接着，探讨了在工程教育专...  0.693889   \n",
      "1    G2FTE  文章首先阐述了工程教育专业认证与应用化学专业生产实习课程之间的关系。其次，探讨了在工程教育专...  0.694830   \n",
      "2    G2FTE  文章首先阐述工程教育专业认证与应用化学生产实习课程的关系。然后探讨工程教育专业认证背景下应用...  0.698251   \n",
      "3    G2FTE  天然产物化学是高等院校药学及相关专业的必修课。课程内容章节丰富且理论性强，学生在学习中面临诸...  0.413904   \n",
      "4    G2FTE  天然药物化学是高校药学及相关专业的必修课。该课程内容广泛且理论性强，对学生的学习造成挑战。因...  0.427470   \n",
      "..     ...                                                ...       ...   \n",
      "529   DSV3  化学作为一门自然科学，是认识和改造世界的重要途径。纵观历史，化学在无数次的实验探索中逐步发展...  0.520751   \n",
      "530   DSV3  化学作为一门自然科学，是人类认识和改造世界的重要途径。纵观历史，化学在无数次的实验探索中逐步...  0.499128   \n",
      "531   DSV3  绿色化学分析技术旨在最小化或避免在分析过程中使用有害化学品，从而实现环境保护和可持续发展。文...  0.518412   \n",
      "532   DSV3  绿色化学分析技术旨在分析过程中尽量减少或避免使用有害化学品，从而实现环境保护和可持续发展。文...  0.528168   \n",
      "533   DSV3  绿色化学分析技术旨在分析过程中尽量减少或避免使用有害化学品，从而实现环境保护和可持续发展。文...  0.527144   \n",
      "\n",
      "         CHRF       TER  Semantic Similarity  \n",
      "0    0.909091  0.141732             0.078745  \n",
      "1    0.909091  0.121337             0.150640  \n",
      "2    0.909091  0.148285             0.184432  \n",
      "3    0.890110  0.072720             0.127360  \n",
      "4    0.813187  0.069251             0.168983  \n",
      "..        ...       ...                  ...  \n",
      "529  0.741071  0.062160             0.067593  \n",
      "530  0.758929  0.062405             0.032716  \n",
      "531  0.793651  0.064128             0.070142  \n",
      "532  0.801587  0.064128             0.070142  \n",
      "533  0.801587  0.064128             0.070142  \n",
      "\n",
      "[534 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the results:\n",
    "print(df[['model', 'EN_ZH', 'BLEU', 'CHRF', 'TER', 'Semantic Similarity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Descriptive Statistics:\n",
      "|       |       BLEU |        CHRF |         TER |   Semantic Similarity |\n",
      "|:------|-----------:|------------:|------------:|----------------------:|\n",
      "| count | 534        | 534         | 534         |           534         |\n",
      "| mean  |   0.601498 |   0.851231  |   0.0808073 |             0.121537  |\n",
      "| std   |   0.108127 |   0.0650691 |   0.101409  |             0.110924  |\n",
      "| min   |   0        |   0         |   0.013339  |             0         |\n",
      "| 25%   |   0.532977 |   0.821892  |   0.0521626 |             0.0532538 |\n",
      "| 50%   |   0.606116 |   0.856105  |   0.0688319 |             0.09194   |\n",
      "| 75%   |   0.678872 |   0.888889  |   0.0867233 |             0.159001  |\n",
      "| max   |   0.834775 |   0.96875   |   1         |             0.658562  |\n",
      "\n",
      "Descriptive Statistics by Model:\n",
      "|                                  |     D S V 3 |   G 2 F T E |\n",
      "|:---------------------------------|------------:|------------:|\n",
      "| ('BLEU', 'count')                | 267         | 267         |\n",
      "| ('BLEU', 'mean')                 |   0.603285  |   0.59971   |\n",
      "| ('BLEU', 'std')                  |   0.102282  |   0.113836  |\n",
      "| ('BLEU', 'min')                  |   0.276982  |   0         |\n",
      "| ('BLEU', '25%')                  |   0.527741  |   0.533788  |\n",
      "| ('BLEU', '50%')                  |   0.605879  |   0.608069  |\n",
      "| ('BLEU', '75%')                  |   0.678086  |   0.679704  |\n",
      "| ('BLEU', 'max')                  |   0.824852  |   0.834775  |\n",
      "| ('CHRF', 'count')                | 267         | 267         |\n",
      "| ('CHRF', 'mean')                 |   0.84943   |   0.853033  |\n",
      "| ('CHRF', 'std')                  |   0.0514739 |   0.0763403 |\n",
      "| ('CHRF', 'min')                  |   0.688889  |   0         |\n",
      "| ('CHRF', '25%')                  |   0.815459  |   0.826856  |\n",
      "| ('CHRF', '50%')                  |   0.846154  |   0.863158  |\n",
      "| ('CHRF', '75%')                  |   0.887049  |   0.893204  |\n",
      "| ('CHRF', 'max')                  |   0.965517  |   0.96875   |\n",
      "| ('TER', 'count')                 | 267         | 267         |\n",
      "| ('TER', 'mean')                  |   0.0808461 |   0.0807685 |\n",
      "| ('TER', 'std')                   |   0.101555  |   0.101454  |\n",
      "| ('TER', 'min')                   |   0.014156  |   0.013339  |\n",
      "| ('TER', '25%')                   |   0.0521687 |   0.0519979 |\n",
      "| ('TER', '50%')                   |   0.0679428 |   0.0689655 |\n",
      "| ('TER', '75%')                   |   0.0869565 |   0.0846942 |\n",
      "| ('TER', 'max')                   |   1         |   1         |\n",
      "| ('Semantic Similarity', 'count') | 267         | 267         |\n",
      "| ('Semantic Similarity', 'mean')  |   0.128719  |   0.114355  |\n",
      "| ('Semantic Similarity', 'std')   |   0.118981  |   0.101953  |\n",
      "| ('Semantic Similarity', 'min')   |   0         |   0         |\n",
      "| ('Semantic Similarity', '25%')   |   0.0532538 |   0.0507053 |\n",
      "| ('Semantic Similarity', '50%')   |   0.101123  |   0.0887031 |\n",
      "| ('Semantic Similarity', '75%')   |   0.166443  |   0.144647  |\n",
      "| ('Semantic Similarity', 'max')   |   0.658562  |   0.573152  |\n"
     ]
    }
   ],
   "source": [
    "# Global Descriptive Statistics\n",
    "global_stats = df[['BLEU', 'CHRF', 'TER', 'Semantic Similarity']].describe()\n",
    "print(\"\\nGlobal Descriptive Statistics:\")\n",
    "print(global_stats.to_markdown())  # Output as markdown for journal\n",
    "\n",
    "# Descriptive Statistics by Model\n",
    "model_stats = df.groupby('model')[['BLEU', 'CHRF', 'TER', 'Semantic Similarity']].describe().transpose()\n",
    "\n",
    "# Flatten the multi-level index for better readability in the table\n",
    "model_stats.columns = [' '.join(col).strip() for col in model_stats.columns.values]\n",
    "\n",
    "print(\"\\nDescriptive Statistics by Model:\")\n",
    "print(model_stats.to_markdown()) # Output as markdown for journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results_metrics/results_metrics.csv\", index=False)\n",
    "df.to_excel(\"results_metrics/results_metrics.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
