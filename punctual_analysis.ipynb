{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import anthropic\n",
    "\n",
    "# Specify the path to your .env file\n",
    "dotenv_path = \"/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/.env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Access and store the environment variable\n",
    "xai_api_key = os.getenv(\"XAI_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "claude_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Config client\n",
    "client_grok = OpenAI(api_key=xai_api_key, base_url=\"https://api.x.ai/v1\")\n",
    "client_gpt = OpenAI(api_key=openai_api_key)\n",
    "client_gemini = genai.Client(api_key=google_api_key)\n",
    "client_ds = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")\n",
    "client_claude = anthropic.Anthropic(api_key=claude_api_key)\n",
    "\n",
    "# Model\n",
    "model_grok = 'grok-beta'\n",
    "model_gpt = 'gpt-4.5-preview-2025-02-27'\n",
    "model_gemini = 'gemini-2.0-flash-thinking-exp'\n",
    "model_ds = 'deepseek-chat'\n",
    "model_claude = 'claude-3-7-sonnet-20250219'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctual_text = \"刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在那江畔上，一江水冷月光满城的汪洋，我在时间的树下等了你很久，尘凡儿缠我谤我笑我白了头，你看那天边追逐落日的纸鸢，像一盏回首道别夤夜的风灯，我的心似流沙放逐在车辙旁，他日你若再返必颠沛在世上，若遇那秋夜雨倦鸟也淋淋，那却是花墙下弥留的枯黄，君住在钱塘东，妾在临安北，君去时褐衣红，小奴家腰上黄，寻差了罗盘经，错投在泉亭，奴辗转到杭城，君又生余杭。”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_and_retranslate(client, model, text):\n",
    "    \"\"\"\n",
    "    Translates the given Chinese text to English and then back to Chinese using the specified client and model.\n",
    "\n",
    "    Args:\n",
    "        client: The client object (OpenAI, genai, or anthropic) to use for translation.\n",
    "        model: The model to use for translation.\n",
    "        text: The Chinese text to translate.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the model name, original text, English translation, and retranslated Chinese text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Translate from ZH to EN\n",
    "    prompt_zh_en = f\"Translate the following Chinese text to English, providing only the translated text without any additional explanations or context: {text}\"\n",
    "    \n",
    "    if isinstance(client, OpenAI):\n",
    "        response_zh_en = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt_zh_en}])\n",
    "        generated_text_zh_en = response_zh_en.choices[0].message.content\n",
    "    elif isinstance(client, genai.Client):\n",
    "        response_zh_en = client.models.generate_content(model=model, contents=prompt_zh_en)\n",
    "        generated_text_zh_en = response_zh_en.text\n",
    "    elif isinstance(client, anthropic.Anthropic):\n",
    "        response_zh_en = client.messages.create(model=model, max_tokens=1000, messages=[{\"role\": \"user\", \"content\": prompt_zh_en}])\n",
    "        generated_text_zh_en = response_zh_en.content[0].text\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported client type.\")\n",
    "\n",
    "    # Step 2: Translate back from EN to ZH\n",
    "    prompt_en_zh = f\"Translate the following English text to Chinese, providing only the translated text without any additional explanations or context: {generated_text_zh_en}\"\n",
    "\n",
    "    if isinstance(client, OpenAI):\n",
    "        response_en_zh = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt_en_zh}])\n",
    "        generated_text_en_zh = response_en_zh.choices[0].message.content\n",
    "    elif isinstance(client, genai.Client):\n",
    "        response_en_zh = client.models.generate_content(model=model, contents=prompt_en_zh)\n",
    "        generated_text_en_zh = response_en_zh.text\n",
    "    elif isinstance(client, anthropic.Anthropic):\n",
    "        response_en_zh = client.messages.create(model=model, max_tokens=1000, messages=[{\"role\": \"user\", \"content\": prompt_en_zh}])\n",
    "        generated_text_en_zh = response_en_zh.content[0].text\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported client type.\")\n",
    "\n",
    "    data = {\n",
    "        'model': [model],\n",
    "        'original_text': [text],\n",
    "        'zh_en': [generated_text_zh_en],\n",
    "        'en_zh': [generated_text_en_zh]\n",
    "    }\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating and retranslating using model: gemini\n",
      "Translation and retranslation complete for model: gemini\n",
      "Translating and retranslating using model: deepseek\n",
      "Translation and retranslation complete for model: deepseek\n",
      "Translating and retranslating using model: claude\n",
      "Translation and retranslation complete for model: claude\n",
      "Translating and retranslating using model: grok\n",
      "Translation and retranslation complete for model: grok\n",
      "Translating and retranslating using model: gpt\n",
      "Translation and retranslation complete for model: gpt\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'gemini': {'model': model_gemini, 'client': client_gemini, 'data': None},\n",
    "    'deepseek': {'model': model_ds, 'client': client_ds, 'data': None},\n",
    "    'claude': {'model': model_claude, 'client': client_claude, 'data': None},\n",
    "    'grok': {'model': model_grok, 'client': client_grok, 'data': None},\n",
    "    'gpt': {'model': model_gpt, 'client': client_gpt, 'data': None}\n",
    "}\n",
    "\n",
    "for model_name, model_data in models.items():\n",
    "    print(f\"Translating and retranslating using model: {model_name}\")\n",
    "    model_data['data'] = translate_and_retranslate(model_data['client'], model_data['model'], punctual_text)\n",
    "    print(f\"Translation and retranslation complete for model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model  \\\n",
      "0  gemini-2.0-flash-thinking-exp   \n",
      "1                  deepseek-chat   \n",
      "2     claude-3-7-sonnet-20250219   \n",
      "3                      grok-beta   \n",
      "4     gpt-4.5-preview-2025-02-27   \n",
      "\n",
      "                                       original_text  \\\n",
      "0  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "1  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "2  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "3  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "4  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "\n",
      "                                               zh_en  \\\n",
      "0  I am the wandering tear on the rings of time,Y...   \n",
      "1  Daolang, excerpt from \"Flower Demon\": \"I am th...   \n",
      "2  Dao Lang, partial lyrics of \"Flower Demon\":\"I ...   \n",
      "3  Here is the translation:Dao Lang, lyrics from ...   \n",
      "4  Dao Lang, lyrics excerpt from \"Hua Yao\":\"I am ...   \n",
      "\n",
      "                                               en_zh  \n",
      "0  我是时间轮环上漂泊的泪滴，你依然能在风中嗅到胭脂的气味。倘若我将誓言刻在那河岸上，一条冰冷的...  \n",
      "1  刀郎，《花妖》节选： \"我是那年轮上流浪的眼泪， 你仍然能闻到风中的胭脂味。 我若是将诺言刻...  \n",
      "2  刀郎，《花妖》部分歌词：\"我是年轮上漂泊的泪，风中尚可闻你的胭脂。若在河滩上刻下誓约，一条寒...  \n",
      "3  刀郎，《花仙子》歌词：“我是年轮上流浪的眼泪，风中还可以闻到胭脂的香气，如果我在河岸上刻下誓...  \n",
      "4  我是年轮上游走的泪， 却让你嗅到风中胭脂的香味。 若在江边刻下一句誓约， 寒江月冷，淹没几座...  \n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for model_name, model_data in models.items():\n",
    "    df = pd.DataFrame(model_data['data'])\n",
    "    # Remove newline characters and excess spaces from all string columns\n",
    "    for col in df.select_dtypes(include='object'):\n",
    "        df[col] = df[col].str.replace('\\n', '', regex=False).str.replace(r'\\s{2,}', ' ', regex=True).str.strip()\n",
    "    df_list.append(df)\n",
    "\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function for Chinese texts using Jieba\n",
    "def tokenize_chinese_jieba(text):\n",
    "    # Use Jieba to cut the Chinese text into words\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# Function to calculate BLEU (using unigram and bigram)\n",
    "def calculate_bleu(candidate_tokens, reference_tokens, weights=(0.5, 0.5, 0.0, 0.0)):\n",
    "    # We use weights (0.5, 0.5) for unigrams and bigrams\n",
    "    try:\n",
    "        return sentence_bleu([reference_tokens], candidate_tokens, weights=weights)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating BLEU: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Function to calculate CHRF (character n-gram F-score)\n",
    "def calculate_chrf(candidate_tokens, reference_tokens):\n",
    "    candidate_str = \"\".join(candidate_tokens)\n",
    "    reference_str = \"\".join(reference_tokens)\n",
    "    # Calculates the ratio between the intersection and the union of the characters of the reference\n",
    "    return len(set(candidate_str) & set(reference_str)) / len(set(reference_str)) if len(set(reference_str)) > 0 else 0\n",
    "\n",
    "# Function to calculate TER using TF-IDF vectorization and mean squared error\n",
    "def calculate_ter(candidate_text, reference_text):\n",
    "    vectorizer = TfidfVectorizer() #token_pattern=r\"(?u)\\b\\w+\\b\" - Removed token pattern because it is not needed for chinese\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([candidate_text, reference_text])\n",
    "        return mean_squared_error(tfidf_matrix[0].toarray(), tfidf_matrix[1].toarray())\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating TER: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Function to calculate Semantic Similarity (TF-IDF + cosine)\n",
    "def calculate_semantic_similarity(original, translated):\n",
    "    vectorizer = TfidfVectorizer() #token_pattern=r\"(?u)\\b\\w+\\b\" - Removed token pattern because it is not needed for chinese\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([original, translated])\n",
    "        return cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating Semantic Similarity: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Apply metrics to each row of the DataFrame\n",
    "def calculate_metrics_for_row(row):\n",
    "    original_text = row['original_text']\n",
    "    en_zh = row['en_zh']\n",
    "\n",
    "    # Tokenize the texts using Jieba\n",
    "    original_tokens = tokenize_chinese_jieba(original_text)\n",
    "    translated_tokens = tokenize_chinese_jieba(en_zh)\n",
    "\n",
    "    # Calculate the metrics:\n",
    "    bleu_value = calculate_bleu(translated_tokens, original_tokens)\n",
    "    chrf_value = calculate_chrf(translated_tokens, original_tokens)\n",
    "    ter_value = calculate_ter(\"\".join(translated_tokens), \"\".join(original_tokens))\n",
    "    semantic_similarity = calculate_semantic_similarity(original_text, en_zh)\n",
    "    bleu_value_uniform = calculate_bleu(translated_tokens, original_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "    return pd.Series([bleu_value, bleu_value_uniform, chrf_value, ter_value, semantic_similarity])\n",
    "\n",
    "def calculate_metrics_for_df(df):\n",
    "    # tqdm.pandas(desc=\"Calculating metrics\") # Removed progress bar\n",
    "    return df.apply(calculate_metrics_for_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model  \\\n",
      "0  gemini-2.0-flash-thinking-exp   \n",
      "1                  deepseek-chat   \n",
      "2     claude-3-7-sonnet-20250219   \n",
      "3                      grok-beta   \n",
      "4     gpt-4.5-preview-2025-02-27   \n",
      "\n",
      "                                       original_text  \\\n",
      "0  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "1  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "2  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "3  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "4  刀郎，《花妖》部分歌词：“我是那年轮上流浪的眼泪，你仍然能闻到风中的胭脂味，我若是将诺言刻在...   \n",
      "\n",
      "                                               zh_en  \\\n",
      "0  I am the wandering tear on the rings of time,Y...   \n",
      "1  Daolang, excerpt from \"Flower Demon\": \"I am th...   \n",
      "2  Dao Lang, partial lyrics of \"Flower Demon\":\"I ...   \n",
      "3  Here is the translation:Dao Lang, lyrics from ...   \n",
      "4  Dao Lang, lyrics excerpt from \"Hua Yao\":\"I am ...   \n",
      "\n",
      "                                               en_zh      BLEU  BLEU-Unif  \\\n",
      "0  我是时间轮环上漂泊的泪滴，你依然能在风中嗅到胭脂的气味。倘若我将誓言刻在那河岸上，一条冰冷的...  0.250627   0.054542   \n",
      "1  刀郎，《花妖》节选： \"我是那年轮上流浪的眼泪， 你仍然能闻到风中的胭脂味。 我若是将诺言刻...  0.760207   0.648145   \n",
      "2  刀郎，《花妖》部分歌词：\"我是年轮上漂泊的泪，风中尚可闻你的胭脂。若在河滩上刻下誓约，一条寒...  0.311400   0.144887   \n",
      "3  刀郎，《花仙子》歌词：“我是年轮上流浪的眼泪，风中还可以闻到胭脂的香气，如果我在河岸上刻下誓...  0.331122   0.150128   \n",
      "4  我是年轮上游走的泪， 却让你嗅到风中胭脂的香味。 若在江边刻下一句誓约， 寒江月冷，淹没几座...  0.214141   0.052313   \n",
      "\n",
      "       CHRF       TER  Semantic Sim  \n",
      "0  0.646259  0.039216      0.000000  \n",
      "1  0.918367  0.025307      0.645701  \n",
      "2  0.646259  0.039795      0.064810  \n",
      "3  0.653061  0.039186      0.020347  \n",
      "4  0.530612  0.043478      0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Assign the calculated metrics to new columns in the original DataFrame\n",
    "metrics_df = calculate_metrics_for_df(final_df)\n",
    "final_df[['BLEU', 'BLEU-Unif', 'CHRF', 'TER', 'Semantic Sim']] = metrics_df.reindex(final_df.index)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results_punctual.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstyles\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alignment, Font, PatternFill\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load the workbook\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m wb = \u001b[43mload_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresults_punctual.xlsx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m ws = wb.active\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Format headers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/bt-conference/.venv/lib/python3.12/site-packages/openpyxl/reader/excel.py:346\u001b[39m, in \u001b[36mload_workbook\u001b[39m\u001b[34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_workbook\u001b[39m(filename, read_only=\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba=KEEP_VBA,\n\u001b[32m    317\u001b[39m                   data_only=\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links=\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    318\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Open the given filename and return the workbook\u001b[39;00m\n\u001b[32m    319\u001b[39m \n\u001b[32m    320\u001b[39m \u001b[33;03m    :param filename: the path to open or a file-like object\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    344\u001b[39m \n\u001b[32m    345\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     reader = \u001b[43mExcelReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mdata_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrich_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m     reader.read()\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m reader.wb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/bt-conference/.venv/lib/python3.12/site-packages/openpyxl/reader/excel.py:123\u001b[39m, in \u001b[36mExcelReader.__init__\u001b[39m\u001b[34m(self, fn, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, read_only=\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba=KEEP_VBA,\n\u001b[32m    122\u001b[39m              data_only=\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links=\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     \u001b[38;5;28mself\u001b[39m.archive = \u001b[43m_validate_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m.valid_files = \u001b[38;5;28mself\u001b[39m.archive.namelist()\n\u001b[32m    125\u001b[39m     \u001b[38;5;28mself\u001b[39m.read_only = read_only\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/bt-conference/.venv/lib/python3.12/site-packages/openpyxl/reader/excel.py:95\u001b[39m, in \u001b[36m_validate_archive\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     88\u001b[39m             msg = (\u001b[33m'\u001b[39m\u001b[33mopenpyxl does not support \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m file format, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     89\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mplease check you can open \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mit with Excel first. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mSupported formats are: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m) % (file_format,\n\u001b[32m     92\u001b[39m                                                    \u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m.join(SUPPORTED_FORMATS))\n\u001b[32m     93\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidFileException(msg)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m archive = \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m archive\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:1331\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1330\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1333\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'results_punctual.xlsx'"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to Excel with good formatting\n",
    "final_df.to_excel('results_metrics/results_punctual.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "# Apply formatting to the Excel file\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment, Font, PatternFill\n",
    "\n",
    "# Load the workbook\n",
    "wb = load_workbook('results_punctual.xlsx')\n",
    "ws = wb.active\n",
    "\n",
    "# Format headers\n",
    "for cell in ws[1]:\n",
    "    cell.font = Font(bold=True)\n",
    "    cell.fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "    cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)\n",
    "\n",
    "# Auto-adjust column widths\n",
    "for column in ws.columns:\n",
    "    max_length = 0\n",
    "    column_letter = column[0].column_letter\n",
    "    for cell in column:\n",
    "        try:\n",
    "            if len(str(cell.value)) > max_length:\n",
    "                max_length = len(str(cell.value))\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = (max_length + 2)\n",
    "    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# Save the formatted workbook\n",
    "wb.save('results_punctual.xlsx')\n",
    "print(\"Results saved to 'results_punctual.xlsx' with formatting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
